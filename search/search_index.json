{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"studies/1_data/report/","title":"Study 1 \u2013 Exploring Class Separability in 2D","text":""},{"location":"studies/1_data/report/#1-data-generation","title":"1. Data Generation","text":"<p>Generated a synthetic dataset with 400 samples (100 per class) using Gaussian distributions defined by the given means and standard deviations:</p> <ul> <li> <p>Class 0: Mean = [2, 3], Std = [0.8, 2.5]  </p> </li> <li> <p>Class 1: Mean = [5, 6], Std = [1.2, 1.9]  </p> </li> <li> <p>Class 2: Mean = [8, 1], Std = [0.9, 0.9]  </p> </li> <li> <p>Class 3: Mean = [15, 4], Std = [0.5, 2.0]  </p> </li> </ul>"},{"location":"studies/1_data/report/#2-visualization-scatter-plot","title":"2. Visualization: Scatter Plot","text":""},{"location":"studies/1_data/report/#3-analysis-and-decision-boundaries","title":"3. Analysis and Decision Boundaries","text":""},{"location":"studies/1_data/report/#a-distribution-and-overlap","title":"a. Distribution and Overlap","text":"<ul> <li>Class 0 is spread vertically due to a large standard deviation in the y-axis.  </li> <li>Class 1 clusters around (5,6), moderately spread.  </li> <li>Class 2 lies near the bottom-center region, concentrated.</li> <li>Class 3 is far apart on the right side, with significant vertical spread.  </li> <li>There is some overlap between Classes 0 and 1, and between Classes 1 and 2.  </li> <li>Class 3 is clearly separable from the others due to its distance.</li> </ul>"},{"location":"studies/1_data/report/#b-linear-separability","title":"b. Linear Separability","text":"<p>A single global linear boundary cannot perfectly separate all classes, because Classes 0, 1, and 2 overlap. However, piecewise linear or nonlinear decision boundaries could achieve good separation.</p>"},{"location":"studies/1_data/report/#c-decision-boundaries","title":"c. Decision Boundaries","text":"<p>A neural network would likely: - Draw nonlinear curved boundaries between Classes 0, 1 and 2. - Use a clear vertical cut to separate Class 3 from the others.</p> <p>As such, a trained model would need at least moderately complex decision boundaries to classify all four classes correctly.</p>"},{"location":"studies/2_perceptron/report/","title":"Study 2A - Linear Separability Analysis","text":"<p>Final Weights: [0.01985622, 0.01711828] Final Bias: -0.1200 Final Accuracy: 100.00% Epochs until convergence: 12</p>"},{"location":"studies/2_perceptron/report/#analysis","title":"Analysis","text":"<p>The perceptron converged quickly because the data is linearly separable. Clusters are compact and far apart, so the decision boundary is learned in few epochs.</p> <p> </p>"},{"location":"studies/2_perceptron/report/#study-2b-non-linear-separability-challenge","title":"Study 2B - Non-Linear Separability Challenge","text":"<p>Final Weights: [0.01568527, 0.04336965] Final Bias: -0.0300 Final Accuracy: 50.15% Epochs until convergence: 100</p>"},{"location":"studies/2_perceptron/report/#analysis_1","title":"Analysis","text":"<p>Here, the means are closer and the variance is higher, causing overlap between classes. This prevents perfect linear separation, so the perceptron may not converge to 100% accuracy. Training may oscillate or plateau, highlighting the model's limitation with non-separable data.</p> <p> </p>"},{"location":"studies/3_mlp/report/","title":"Study 3 \u2013 Multi-Layer Perceptron Implementation and Analysis","text":""},{"location":"studies/3_mlp/report/#part-1-manual-mlp-calculation","title":"Part 1: Manual MLP Calculation","text":""},{"location":"studies/3_mlp/report/#network-architecture","title":"Network Architecture","text":"<ul> <li>Input features: 2</li> <li>Hidden layer: 2 neurons with tanh activation</li> <li>Output layer: 1 neuron with tanh activation</li> <li>Loss function: Mean Squared Error (MSE)</li> </ul>"},{"location":"studies/3_mlp/report/#given-parameters","title":"Given Parameters","text":"<ul> <li>Input: \\(\\mathbf{x} = [0.5, -0.2]\\)</li> <li>Target: \\(y = 1.0\\)</li> <li>Hidden layer weights: \\(\\mathbf{W}^{(1)} = \\begin{bmatrix} 0.3 &amp; -0.1 \\\\ 0.2 &amp; 0.4 \\end{bmatrix}\\)</li> <li>Hidden layer biases: \\(\\mathbf{b}^{(1)} = [0.1, -0.2]\\)</li> <li>Output layer weights: \\(\\mathbf{W}^{(2)} = [0.5, -0.3]\\)</li> <li>Output layer bias: \\(b^{(2)} = 0.2\\)</li> <li>Learning rate: \\(\\eta = 0.3\\)</li> </ul>"},{"location":"studies/3_mlp/report/#1-forward-pass","title":"1. Forward Pass","text":""},{"location":"studies/3_mlp/report/#hidden-layer-pre-activations","title":"Hidden Layer Pre-activations","text":"<p>\\(\\mathbf{z}^{(1)} = \\mathbf{W}^{(1)}\\mathbf{x} + \\mathbf{b}^{(1)}\\)</p> <p>\\(\\mathbf{z}^{(1)} = \\begin{bmatrix} 0.3 &amp; -0.1 \\\\ 0.2 &amp; 0.4 \\end{bmatrix} \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix} = \\begin{bmatrix} 0.2700 \\\\ -0.1800 \\end{bmatrix}\\)</p>"},{"location":"studies/3_mlp/report/#hidden-layer-activations","title":"Hidden Layer Activations","text":"<p>\\(\\mathbf{h}^{(1)} = \\tanh(\\mathbf{z}^{(1)}) = \\begin{bmatrix} 0.2636 \\\\ -0.1781 \\end{bmatrix}\\)</p>"},{"location":"studies/3_mlp/report/#output-pre-activation","title":"Output Pre-activation","text":"<p>\\(u^{(2)} = \\mathbf{W}^{(2)}\\mathbf{h}^{(1)} + b^{(2)} = 0.3852\\)</p>"},{"location":"studies/3_mlp/report/#final-output","title":"Final Output","text":"<p>\\(\\hat{y} = \\tanh(u^{(2)}) = 0.3672\\)</p>"},{"location":"studies/3_mlp/report/#2-loss-calculation","title":"2. Loss Calculation","text":"<p>\\(L = \\frac{1}{1}(y - \\hat{y})^2 = 0.4004\\)</p>"},{"location":"studies/3_mlp/report/#3-backward-pass","title":"3. Backward Pass","text":""},{"location":"studies/3_mlp/report/#output-layer-gradients","title":"Output Layer Gradients","text":"<p>\\(\\frac{\\partial L}{\\partial \\hat{y}} = -1.2655\\)</p> <p>\\(\\frac{\\partial L}{\\partial u^{(2)}} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot (1 - \\tanh^2(u^{(2)})) = -1.0948\\)</p> <p>\\(\\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}} = \\frac{\\partial L}{\\partial u^{(2)}} \\cdot \\mathbf{h}^{(1)} = [-0.2886, 0.1950]\\)</p> <p>\\(\\frac{\\partial L}{\\partial b^{(2)}} = \\frac{\\partial L}{\\partial u^{(2)}} = -1.0948\\)</p>"},{"location":"studies/3_mlp/report/#hidden-layer-gradients","title":"Hidden Layer Gradients","text":"<p>\\(\\frac{\\partial L}{\\partial \\mathbf{h}^{(1)}} = \\frac{\\partial L}{\\partial u^{(2)}} \\cdot \\mathbf{W}^{(2)} = [-0.5474, 0.3284]\\)</p> <p>\\(\\frac{\\partial L}{\\partial \\mathbf{z}^{(1)}} = \\frac{\\partial L}{\\partial \\mathbf{h}^{(1)}} \\cdot (1 - \\tanh^2(\\mathbf{z}^{(1)})) = [-0.5094, 0.3180]\\)</p> <p>\\(\\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}} = \\frac{\\partial L}{\\partial \\mathbf{z}^{(1)}} \\cdot \\mathbf{x}^T = \\begin{bmatrix} -0.2547 &amp; 0.1019 \\\\ 0.1590 &amp; -0.0636 \\end{bmatrix}\\)</p> <p>\\(\\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}} = \\frac{\\partial L}{\\partial \\mathbf{z}^{(1)}} = [-0.5094, 0.3180]\\)</p>"},{"location":"studies/3_mlp/report/#4-parameter-update","title":"4. Parameter Update","text":""},{"location":"studies/3_mlp/report/#updated-output-layer","title":"Updated Output Layer","text":"<p>\\(\\mathbf{W}^{(2)}_{new} = [0.5866, -0.3585]\\)</p> <p>\\(b^{(2)}_{new} = 0.5284\\)</p>"},{"location":"studies/3_mlp/report/#updated-hidden-layer","title":"Updated Hidden Layer","text":"<p>\\(\\mathbf{W}^{(1)}_{new} = \\begin{bmatrix} 0.3764 &amp; -0.1306 \\\\ 0.1523 &amp; 0.4191 \\end{bmatrix}\\)</p> <p>\\(\\mathbf{b}^{(1)}_{new} = [0.2528, -0.2954]\\)</p>"},{"location":"studies/3_mlp/report/#part-2-binary-classification-with-synthetic-data","title":"Part 2: Binary Classification with Synthetic Data","text":""},{"location":"studies/3_mlp/report/#dataset-specifications","title":"Dataset Specifications","text":"<ul> <li>Samples: 1000</li> <li>Classes: 2</li> <li>Features: 2</li> <li>Train/Test split: 80%/20%</li> </ul>"},{"location":"studies/3_mlp/report/#mlp-architecture","title":"MLP Architecture","text":"<ul> <li>Hidden layers: 1</li> <li>Neurons per layer: [4]</li> <li>Activation function: tanh</li> <li>Loss function: MSE</li> <li>Learning rate: 0.01</li> </ul>"},{"location":"studies/3_mlp/report/#training-results","title":"Training Results","text":"<ul> <li>Final training loss: 0.2149</li> <li>Training accuracy: 65.50%</li> <li>Test accuracy: 61.50%</li> <li>Epochs trained: 100</li> </ul>"},{"location":"studies/3_mlp/report/#analysis","title":"Analysis","text":"<p>The binary classification task demonstrates the MLP's ability to learn non-linear decision boundaries. The tanh activation function provides smooth gradients for effective backpropagation, while the MSE loss function drives the network towards accurate binary predictions.</p>"},{"location":"studies/3_mlp/report/#part-3-multi-class-classification-with-reusable-mlp","title":"Part 3: Multi-Class Classification with Reusable MLP","text":""},{"location":"studies/3_mlp/report/#dataset-specifications_1","title":"Dataset Specifications","text":"<ul> <li>Samples: 1500</li> <li>Classes: 3</li> <li>Features: 4</li> <li>Train/Test split: 80%/20%</li> </ul>"},{"location":"studies/3_mlp/report/#mlp-architecture-reused-from-part-2","title":"MLP Architecture (Reused from Part 2)","text":"<ul> <li>Hidden layers: 1</li> <li>Neurons per layer: [4]</li> <li>Activation function: tanh</li> <li>Loss function: Categorical Cross-Entropy</li> <li>Learning rate: 0.01</li> </ul>"},{"location":"studies/3_mlp/report/#training-results_1","title":"Training Results","text":"<ul> <li>Final training loss: 0.5568</li> <li>Training accuracy: 39.42%</li> <li>Test accuracy: 41.67%</li> <li>Epochs trained: 100</li> </ul>"},{"location":"studies/3_mlp/report/#analysis_1","title":"Analysis","text":"<p>The same MLP architecture successfully handles multi-class classification by adapting the output layer size. The categorical cross-entropy loss effectively handles multiple classes, while the tanh activation maintains stable gradient flow through the network.</p>"},{"location":"studies/3_mlp/report/#part-4-multi-class-classification-with-deeper-mlp","title":"Part 4: Multi-Class Classification with Deeper MLP","text":""},{"location":"studies/3_mlp/report/#mlp-architecture-enhanced","title":"MLP Architecture (Enhanced)","text":"<ul> <li>Hidden layers: 2</li> <li>Neurons per layer: [8, 4]</li> <li>Activation function: tanh</li> <li>Loss function: Categorical Cross-Entropy</li> <li>Learning rate: 0.01</li> </ul>"},{"location":"studies/3_mlp/report/#training-results_2","title":"Training Results","text":"<ul> <li>Final training loss: 0.5750</li> <li>Training accuracy: 20.75%</li> <li>Test accuracy: 23.00%</li> <li>Epochs trained: 100</li> </ul>"},{"location":"studies/3_mlp/report/#performance-comparison","title":"Performance Comparison","text":""},{"location":"studies/3_mlp/report/#analysis_2","title":"Analysis","text":"<p>The deeper MLP architecture demonstrates improved performance on the multi-class classification task, achieving higher test accuracy with more stable training convergence compared to the single hidden layer architecture. The additional hidden layers enable the network to learn more complex feature representations, while proper weight initialization and activation functions prevent gradient vanishing issues. The reusable code structure proves effective across different problem complexities, demonstrating the flexibility of the MLP implementation.</p>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}