{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"exercises/1_data.md/main/","title":"Exercise 1 \u2013 Exploring Class Separability in 2D","text":""},{"location":"exercises/1_data.md/main/#1-data-generation","title":"1. Data Generation","text":"<p>Generated a synthetic dataset with 400 samples (100 per class) using Gaussian distributions defined by the given means and standard deviations:</p> <ul> <li>Class 0: Mean = [2, 3], Std = [0.8, 2.5]  </li> <li>Class 1: Mean = [5, 6], Std = [1.2, 1.9]  </li> <li>Class 2: Mean = [8, 1], Std = [0.9, 0.9]  </li> <li>Class 3: Mean = [15, 4], Std = [0.5, 2.0]</li> </ul>"},{"location":"exercises/1_data.md/main/#2-visulization-scatter-plot","title":"2. Visulization: Scatter Plot","text":""},{"location":"exercises/1_data.md/main/#3-analysis-and-decision-boundaries","title":"3. Analysis and Decision Boundaries","text":""},{"location":"exercises/1_data.md/main/#a-distribution-and-overlap","title":"a. Distribution and Overlap","text":"<ul> <li>Class 0 is spread vertically due to a large standard deviation in the y-axis.  </li> <li>Class 1 clusters around (5,6), moderately spread.  </li> <li>Class 2 lies near the bottom-center region, concentrated.</li> <li>Class 3 is far apart on the right side, with significant vertical spread.  </li> <li>There is some overlap between Classes 0 and 1, and between Classes 1 and 2.  </li> <li>Class 3 is clearly separable from the others due to its distance.</li> </ul>"},{"location":"exercises/1_data.md/main/#b-linear-separability","title":"b. Linear Separability","text":"<p>A single global linear boundary cannot perfectly separate all classes, because Classes 0, 1, and 2 overlap. However, piecewise linear or nonlinear decision boundaries could achieve good separation.</p>"},{"location":"exercises/1_data.md/main/#c-decision-boundaries","title":"c. Decision Boundaries","text":"<p>A neural network would likely: - Draw nonlinear curved boundaries between Classes 0, 1 and 2. - Use a clear vertical cut to separate Class 3 from the others.</p> <p>As such, a trained model would need at least moderately complex decision boundaries to classify all four classes correctly. In terms of visual separation, without overfitting the model, it would be similar to this:</p> <p></p>"},{"location":"exercises/1_data.md/main/#exercise-2-non-linearity-in-higher-dimensions","title":"Exercise 2 \u2013 Non-Linearity in Higher Dimensions","text":""},{"location":"exercises/1_data.md/main/#1-data-generation-5d","title":"1. Data Generation (5D)","text":"<p>Generated 1,000 samples using multivariate normal distributions (500 per class).</p> <ul> <li>Class A \u2014 mean \u03bc_A = [0, 0, 0, 0, 0], covariance \u03a3_A:</li> </ul> <p>Covariance matrix for Class A:</p> x\u2081 x\u2082 x\u2083 x\u2084 x\u2085 x\u2081 1.0 0.8 0.1 0.0 0.0 x\u2082 0.8 1.0 0.3 0.0 0.0 x\u2083 0.1 0.3 1.0 0.5 0.0 x\u2084 0.0 0.0 0.5 1.0 0.2 x\u2085 0.0 0.0 0.0 0.2 1.0 <ul> <li>Class B \u2014 mean \u03bc_B = [1.5, 1.5, 1.5, 1.5, 1.5], covariance \u03a3_B:</li> </ul> <p>Covariance matrix for Class B:</p> x\u2081 x\u2082 x\u2083 x\u2084 x\u2085 x\u2081 1.5 -0.7 0.2 0.0 0.0 x\u2082 -0.7 1.5 0.4 0.0 0.0 x\u2083 0.2 0.4 1.5 0.6 0.0 x\u2084 0.0 0.0 0.6 1.5 0.3 x\u2085 0.0 0.0 0.0 0.3 1.5"},{"location":"exercises/1_data.md/main/#2-dimensionality-reduction-visualization","title":"2. Dimensionality Reduction &amp; Visualization","text":"<p>Applied PCA (5D \u2192 2D) resulting in the following distribution:</p> <p></p>"},{"location":"exercises/1_data.md/main/#3-analysis","title":"3. Analysis","text":""},{"location":"exercises/1_data.md/main/#a-relationship-between-classes","title":"a. Relationship between classes.","text":"<p>In the 2D PCA view, the classes form two clusters with partial overlap. Class B tends to shift along PC1 because of its higher mean vector, while both classes spread along PC2 due to similar variance/correlation patterns in their covariances.</p>"},{"location":"exercises/1_data.md/main/#b-linear-separability_1","title":"b. Linear separability.","text":"<p>The data are not cleanly linearly separable. Different covariance structures (including opposite-signed correlations) plus only a moderate mean shift cause interleaving along some directions. PCA is unsupervised, so it may mix class information in the top components, increasing overlap in 2D. A single linear boundary (e.g., a Perceptron) will struggle; a multi-layer neural network with non-linear activations (or kernel methods) can learn curved boundaries in the original 5D space that better align with the geometry and separate the classes more accurately.</p>"},{"location":"exercises/1_data.md/main/#exercise-3-preparing-real-world-data-for-a-neural-network","title":"Exercise 3 \u2013 Preparing Real-World Data for a Neural Network","text":""},{"location":"exercises/1_data.md/main/#1-dataset-objective","title":"1. Dataset Objective","text":"<p>The dataset comes from the Kaggle Spaceship Titanic competition. - The target column is <code>Transported</code>, which indicates whether a passenger was transported to an alternate dimension after the spaceship accident. - This is a binary classification task.</p>"},{"location":"exercises/1_data.md/main/#2-dataset-overview","title":"2. Dataset Overview","text":"Numerical Features Categorical Features Age HomePlanet RoomService CryoSleep FoodCourt Cabin ShoppingMall Destination Spa VIP VRDeck"},{"location":"exercises/1_data.md/main/#target-feature","title":"Target Feature","text":"<ul> <li><code>Transported</code> (True/False)</li> </ul>"},{"location":"exercises/1_data.md/main/#missing-values","title":"Missing Values","text":"<ul> <li>All categories have missing values except for the <code>target</code> feature, around 200 occurences per feature with slightly less in most of them.</li> </ul>"},{"location":"exercises/1_data.md/main/#3-preprocessing-steps","title":"3. Preprocessing Steps","text":""},{"location":"exercises/1_data.md/main/#a-handling-missing-data","title":"a. Handling Missing Data","text":"<ul> <li>For numerical features, missing values are imputed with the median, which is robust to skewed spending distributions.  </li> <li>For categorical features, missing values are imputed with the mode (most frequent category).  </li> <li>This ensures no rows are dropped unnecessarily and that the replaced data is closer to the \"reality\" within the sample.</li> </ul>"},{"location":"exercises/1_data.md/main/#b-encoding-categorical-features","title":"b. Encoding Categorical Features","text":"<ul> <li>One-hot encoding is applied to categorical features (<code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code>).  </li> <li>This avoids ordinal assumptions and allows the network to learn separate weights per category.</li> </ul>"},{"location":"exercises/1_data.md/main/#c-scaling-numerical-features","title":"c. Scaling Numerical Features","text":"<ul> <li>Numerical columns are standardized to mean = 0, std = 1.  </li> <li>This is preferred since the neural network uses a tanh activation function:</li> <li><code>tanh</code> outputs values in [-1, 1].  </li> <li>Centering inputs at zero with standardization accelerates convergence and stabilizes learning.</li> </ul>"},{"location":"exercises/1_data.md/main/#4-visualization-of-transformations","title":"4. Visualization of Transformations","text":""},{"location":"exercises/1_data.md/main/#histograms-of-age-and-foodcourt-before-and-after-scaling","title":"histograms of <code>Age</code> and <code>FoodCourt</code> before and after scaling.","text":"<ul> <li>Results:</li> <li>Before scaling: raw distributions with arbitrary ranges (e.g., Age in years, FoodCourt in credits).  </li> <li>After scaling: centered around 0, standardized variance, which matches the activation range of tanh.  </li> <li>Almost if not identical data distribution.</li> </ul>"},{"location":"exercises/1_data.md/main/#5-conclusion","title":"5. Conclusion","text":"<p>The dataset has been cleaned, encoded, and standardized so it is ready to be fed into a neural network using <code>tanh</code> activation. This preprocessing ensures: - Missing data does not harm training. - Categorical variables are machine-readable. - Input scale matches the requirements of the chosen activation function.</p>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/main/","title":"Roteiro 1","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Roteiro 2","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Roteiro 3","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> </p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-08-29T19:35:50.508709 image/svg+xml Matplotlib v3.10.5, https://matplotlib.org/ <pre><code>Traceback (most recent call last):\n  File \"C:\\Users\\pedro\\Desktop\\Redes Neurais\\data-augmentation-experiment\\env\\Lib\\site-packages\\markdown_exec\\_internal\\formatters\\python.py\", line 71, in _run_python\n    exec_python(code, code_block_id, exec_globals)\n  File \"C:\\Users\\pedro\\Desktop\\Redes Neurais\\data-augmentation-experiment\\env\\Lib\\site-packages\\markdown_exec\\_internal\\formatters\\_exec_python.py\", line 8, in exec_python\n    exec(compiled, exec_globals)  # noqa: S102\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;code block: n2&gt;\", line 21, in &lt;module&gt;\n    f = np.poly1d(np.polyfit(x, close, order_poly))\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\pedro\\Desktop\\Redes Neurais\\data-augmentation-experiment\\env\\Lib\\site-packages\\numpy\\lib\\_polynomial_impl.py\", line 645, in polyfit\n    raise TypeError(\"expected non-empty vector for x\")\nTypeError: expected non-empty vector for x\n</code></pre> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}